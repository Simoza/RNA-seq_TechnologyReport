---
title: "How to perform RNA-sequencing"
subtitle: "Technology report - 4 hp"
author: "Simone Zaghen"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document: 
    toc: true
    number_section: true
#    toc_float: 
#      collapsed: false
#      smooth_scroll: true
#  bookdown::word_document2:
#    reference_docx: template.docx
#    toc: true
#    number_section: true
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../results/Reports") })
---

<style>
body {
text-align: justify}
</style>

```{r, include=FALSE, message=FALSE}
library(knitr)
library(kableExtra)

```

# Introduction

This advanced technology report describes a [limma-based approach](https://bioconductor.org/packages/release/bioc/html/limma.html) to analyze RNA sequencing data and extract gene-level statistics to perform gene set analysis using the package [PIANO](https://bioconductor.org/packages/release/bioc/html/piano.html) (**P**latform for **i**ntegrative **an**alysis of **o**mics data). The report is mainly focused on the analysis performed after generating a gene-count file with the [nf-core RNA-seq pipeline](https://github.com/nf-core/rnaseq). How to map the reads to a reference genome will be briefly discussed from a theoretical point of view, but no code will be shown or discussed. After a brief introduction on RNA-sequencing principles, the code used to perform the analysis will be described and explained step by step. The procedure and results are based on *Y. lipolitica* but can be easily adjusted to different organisms as well. All the code is available [in this GitHub directory](https://github.com/Simoza/RNA-seq_TechnologyReport).

# RNA-sequencing principles

RNA-sequencing is a technique that aims to sequence and quantify the transcriptome of a cell. Given a specific physiological condition, the transcriptome is the complete set of transcripts and their quantity in a cell. Understanding the transcriptome is essential to interpret the functional elements of the genome, to reveal the molecular processes that are taking place in a cell, and to infer which regulation mechanisms underline specific phenotypic responses.

In general, a population of RNA (total population or mRNA-enriched) is converted to a library of cDNA fragments with adapters attached to one or both ends (Figure \@ref(fig:DiagramRNA)). Each molecule is then sequenced to obtain short sequences from one end in case of single-end sequencing or both ends in case of pair-end sequencing. The reads usually have a length between 30 and 400 bp, depending on the sequencing technology used. Following sequencing, the reads are trimmed to remove nucleotides with low quality scores, and then aligned to a reference genome to quantify gene counts. The output of this procedure is a file for which each row represents a gene name, and each column a sample; the intersections are the gene counts. 

```{r DiagramRNA, echo= FALSE, fig.cap= "RNAs are first fragmented and then converted into a library of cDNA fragments. Sequencing adaptors are subsequently ligated to each cDNA fragment. Through high-throughput sequencing technologies a short sequencing is obtained from each cDNA. The resulting sequence reads are aligned with the reference genome or transcriptome to generate a base-resolution expression profile for each gene. Adapted from [Wang, Zhong et al. (2009)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2949280/)"}

include_graphics("../docs/figures/fig_1/fig1.jpg")

```

## Isolation of RNA

The first step in RNA-sequencing is the isolation of RNA. In our experiments we extracted RNA with the [RNeasy kit from Qiagen](https://www.qiagen.com/us/products/discovery-and-translational-research/dna-rna-purification/rna-purification/total-rna/rneasy-kits/). Biological samples are first lysed and homogenized in the presence of a highly denaturing guanidine-thiocyanate–containing buffer. This buffer inactivates RNases and ensures purification of intact RNA. After adding ethanol to provide appropriate binding conditions, the sample is loaded on a silica-based column. The total RNA binds to the matrix of the column, and few washing steps ensure removal of contaminants. Finally, RNA can be eluted in milliQ-water.

After RNA extraction, the quality of the extracted RNA needs to be assessed. The quality of RNA is typically measured through a Bioanalyzer (Agilent Technologies), an automated electrophoresis system that can monitor and estimate the RNA quality of the samples. The Bioanalyzer calculates a RIN value (RNA Integrity Number), a number between 1 and 10, where 10 represent high quality samples showing the least degradation. The RIN value estimates sample integrity and is calculated based on the ratios of 28S and 18S ribosomal bands. Since the RIN values are based on the abundance of 28S and 18S of mammalian cells, cells with different ribosomal ratios may generate low RIN numbers that do not necessarily correlate with low sample quality. Usually for yeasts such as *Y. lipolytica* and *S. cerevisiae* RIN values between 7-8 produce libraries that can be successfully sequenced. Low-quality RNA should not be sequenced since RNA degradation affects the sequencing results due to uneven gene coverage and 3′–5′ transcript bias, and would lead to erroneous quantification and thus erroneous biological interpretation of the data.

## Library preparation and sequencing

Before constructing a library for the sequencing, it is necessary to enrich or deplete the total RNA sample from particular RNA species. The total RNA pool includes ribosomal RNA (rRNA), precursor messenger RNA (pre-mRNA), mRNA, and various classes of non-coding RNA such as tRNA, miRNA, small RNA, long non coding RNA, etc. rRNA is the most abundant RNA specie and can account for over 95% of the total cellular RNA (REF). It it thus necessary to deplete the rRNA to avoid consuming the bulk of the sequencing reads, limiting the detection of other less-abundant RNAs. Depending on the goal of the analysis and depending on which class of RNA we want to sequence, many enrichment (or depletion) protocols have been designed ([REF](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4863231/)).

```{r EnrichmentMethods, echo=FALSE}
table1 <- read.csv2("../docs/tables/Table1.csv")
colnames(table1)[1] <- "Library design"
kable(table1, caption = "Enrichment or depletion methods") %>%
  kable_styling("striped")
rm("table1")

```

The most commonly used protocol to study the mRNA profile of the cell consists in poly-A enrichment. In this approach, the 3′ poly-A tail of mRNA molecules is targeted using poly-T oligos that are covalently attached to a given substrate such as magnetic beads. Following this enrichment step, the mRNA is fragmented and these fragments are copied into the first strand of cDNA using reverse transcriptase and random primers. After the first strand of cDNA is synthetised, dTTP are replaced with dUTP and the second strand of cDNA is synthetised. At this point, a single 'A' nucleotide is ligated to the 3' ends of the blunt fragments, creating overhangs. The adapter has a 'T' nucleotide in the 3' tail and it has a complementarity overhang to the fragment to which it needs to be ligated. The adapters ensure that the fragments that need to be sequenced attache to the sequencing flow cell (REF).

The sequencing industry has been dominated by Illumina, which applies an ensemble-based (sequencing many identical copies of a DNA molecule) sequencing-by-synthesis approach. Using fluorescently labeled reversible-terminator nucleotides, DNA molecules are clonally amplified while immobilized on the surface of a glass flowcell. Currently, the Illumina HiSeq platform is the most commonly applied next-generation sequencing technology for RNA-Seq and has set the standard for NGS sequencing. The platform has two flow cells, each providing eight separate lanes for sequencing reactions to occur (REF). 

## From sequencing to gene counts

There are many steps separating the RNA sequencing  and the generation of the gene count file. These steps will be described briefly, but more literature and documentation can be found [here](https://github.com/nf-core/rnaseq) and [here](https://training.galaxyproject.org/training-material/topics/transcriptomics/tutorials/rna-seq-reads-to-counts/tutorial.html).

The analysis begins with the generation of the sequencing reads. For each sample the output  is a single FASTQ file if performing single-end sequencing, or two FASTQ files for double-end sequencing. A FASTQ file is a text-based file format for storing both a nucleotide sequence and its corresponding quality scores for the sequencing. After obtaining FASTQ files, the first step is performing quality control on the reads. During sequencing, errors might be introduced, such as incorrect nucleotides. Every base sequence gets a quality score from the sequencer and this information is present in the FASTQ file. At this step, the base quality of all samples should be checked. It is also necessary to check if the Illumina adapters have been  sequenced. To perform this step the [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) or [MultiQC](https://github.com/ewels/MultiQC) packages can be used. In case adapters have been sequenced, it is necessary to trim the reads to remove the  adapter and to remove any low quality bases at the ends of the read. Sequences that will be too short ( usually < 20bp) will be discarded. This step can be performed with [Trim Galore](https://github.com/FelixKrueger/TrimGalore). 

After these preprocessing steps, the reads can be aligned. For *Y. lipolytica* and *S. cerevisiae* reference genomes that can be used to map the reads are available. To perform the alignment [STAR](https://github.com/alexdobin/STAR) can be used. The alignment produces a set of BAM files, where each file contains the chromosomal location for every read that was mapped. The mapped reads can now be counted across genes by using a tool called [Salmon](https://github.com/COMBINE-lab/salmon) that quantifies the reads mapped to exons and produces the read count for each gene.

# Differential gene expression analysis

I will now describe all the steps required to perform differential gene expression analysis. Differential gene expression analysis consists in taking the normalized read count data and performing statistical analysis to discover quantitative changes in expression levels between experimental groups.

## Install the required packages

The first step is installing all the packages required to perform the analysis.

```{r, results='hide', message=FALSE, warning=FALSE}
# Install and load packages from bioconductor
if (!require("BiocManager", quietly = TRUE)) install.packages("BiocManager")
if (!require("limma", quietly = TRUE)) BiocManager::install("limma"); library(limma)
if (!require("edgeR", quietly = TRUE)) BiocManager::install("edgeR"); library(edgeR)
if (!require("piano", quietly = TRUE)) BiocManager::install("piano"); library(piano)
if (!require("EnhancedVolcano", quietly = TRUE)) BiocManager::install("EnhancedVolcano"); library(EnhancedVolcano)

#Install and load packages from CRAN
if (!require('tidyverse')) install.packages('tidyverse'); library('tidyverse')
if (!require('RColorBrewer')) install.packages('RColorBrewer'); library('RColorBrewer')
if (!require('ggpubr')) install.packages('ggpubr'); library('ggpubr')
if (!require('gplots')) install.packages('gplots'); library('gplots')
if (!require('gridExtra')) install.packages('gridExtra'); library('gridExtra')
if (!require('eulerr')) install.packages('eulerr'); library('eulerr')
if (!require('snowfall')) install.packages('snowfall'); library('snowfall')

```

Now we create the directories in which we will save the results.

```{r, results='hide', message=FALSE}
if (!dir.exists("../results/")){dir.create("../results/")}
if (!dir.exists("../results/Output_Preprocessing")){dir.create("../results/Output_Preprocessing")}
if (!dir.exists("../results/Comparison_Output")){dir.create("../results/Comparison_Output")}

```

## Preprocessing

In the pre-processing step we are going to load our data, filter genes with low reads, and normalize the gene counts. 

### Load the data

To perform differential gene expression analysis, we need a file containing the gene counts of our samples. The rows contain the gene name and each column corresponds to a sample. At the intersection the read counts of a specific gene for a specific sample are reported. 

```{r}
gene_counts <- read.csv2("../data/gene_counts.csv", row.names = 1 )

```

The count matrix looks like this:

```{r GeneCounts, echo=FALSE}
kable(gene_counts[316:326, 1:9]) %>%
  kable_styling("striped")

```

To perform downstream analysis and draw conclusions, sample-level information related to the experiment needs to be associated with the columns (samples) of the counts matrix. The metadata should include experimental variables that could have an effect on expression levels.

```{r}
metadata <- read.csv2('../data/metadata.csv', skip =0) #import metadata
cols <- c("Strain","NitrogenSource","CN_Ratio","DR") #columns to convert to factors
metadata[cols] <- lapply(metadata[cols], factor) #convert columns to factors
rm("cols") #remove cols variable from environment

```

The metadata look like this:
```{r metadata, echo=FALSE}
kable(metadata[1:10,1:5]) %>%
  kable_styling("striped")

```

Now that we have the gene_counts and the metadata, we can create a DGEList, the object we will use to perform the analysis. The DGEList function takes gene counts, gene names, a dataframe containing sample metadata, and a group as input arguments. The function will associate the first column of the gene_count matrix (so the first sample) with the first level of the samples argument, which contains the metadata of the samples. This means that the samples in the columns of gene_counts need to be in the same order as the samples in the metadata dataframe. Performing this step will associate the gene_counts information with all the experimental variables that are included in the metadata (in this example strain, dilution rate, nitrogen source, and C/N ratio) and will allow to easily subset for specific conditions. 
The output of the DGEList function is a list that includes three objects:

1. **Counts**: this is a numeric vector that contains the gene counts information,

2. **Samples**: this is a dataframe in which the metadata information are saved. When running the DGEList function, new column are also added to the dataframe. One column called "group" stores the information about experimental groups. In this case, the information about the experimental group can be piped into the function by specifying a "group" argument that is generated by pasting the experimental variables separated by an underscore. The DGEList function also calculates and stores the information of the library size, a number reporting the total counts (sequencing depth) for each library. This information is stored in the "lib.size" column. In the dataframe we also get a column called "norm.factors". Stored in this column is the information on the normalization factor to apply to normalize gene counts across libraries with different sizes. At the moment every normalization factor is 1 because we haven't calculated the normalization factors yet.

3. **Genes**: a character vector storing the names of the genes.


```{r}
#Create DGEList and add the metadata of the samples
x <- DGEList(counts = gene_counts, 
             genes = rownames(gene_counts), 
             samples = metadata,
             group = paste(metadata$Strain,
                           metadata$NitrogenSource,
                           metadata$CN_Ratio,
                           metadata$DR,
                           sep = "_"))
```

### Filter low reads

Before performing differential gene expression analysis, we need to remove genes that have read counts that are too low to be retained in a statistical analysis. We need to perform this filtering step for several reasons:

* genes with low gene counts in all samples provide little evidence for differential expression;

* often samples contain many genes with very low gene counts or with gene counts equal to zero;

* testing for many differentially expressed genes simultaneously contributes to the multiple testing burden. 

The multiple comparisons burden arise when a statistical analysis involves multiple statistical tests. For each set of tests, a p-value is usually applied as cutoff between accepting or rejecting the null hypothesis. As the number of tests increases, it becomes more likely that the groups will differ for at least one feature by chance, since with a p value of 0.05 we expect a 5% probability of rejecting a null hypothesis. Scaling up the numbers, if we are performing 1000 comparisons to analyse differentially expressed genes, and each comparison is performed with a significance level at 0.05, the expected number of gene falsely detected genes as differentially expressed is 50. This would reduce the reliability of our analysis and conclusions. To prevent the multiple test burden, several methods have been developed, for example  the Bonferroni method, or  the Benjamini and Hochberg method. These methods aim to prevent the inflation of false positive rates that occurs with multiple statistical testings by adjusting the p-value.

To remove genes with low reads, it is necessary to perform a filtering step before continuing with the analysis. The filtering step cannot be performed on raw read counts since raw gene counts do not account for different library sizes. There are several ways to account for library sizes, some of which also account for gene length, since longer genes have higher probability of having more reads mapped to them. Even though the methods that account for both library size and gene length are more accurate, we will use the log<sub>2</sub>-CPM (log<sub>2</sub> count per million) values that only account for library size, mainly for two reasons. First, since log<sub>2</sub>-CPM only account for library size, we don't need to feed information about the length of each gene in the dataset. The counts matrix alone is sufficient to calculate log<sub>2</sub>-CPM. Second, since the gene lengths remain constant among samples because we are using the same organism, any observed differences are a result of changes in condition rather than changes in gene length.

Therefore, we first convert raw gene counts to log<sub>2</sub>-CPM to account for differences in sequencing depth between samples, and then we perform a filtering step with the function "filterByExpr". Quoting the manual, "the filterByExpr function keeps genes that have worthwhile counts in a minimum number of samples". In our case the minimum number of samples is at least three samples since the smallest group size is three. The function accesses the group factor contained in the DGEList in order to compute the minimum group size, but the filtering is performed independently of which sample belongs to which group so that no bias is introduced. After determining the minimum group size, the function calculates the median library size and uses that value to determine a CPM.Cutoff. The CPM.Cutoff is defined as the ratio between the min.count (as default is set at 10) adjusted to 10<sup>6</sup> to convert to count-per-million, and the median library size. Calculated this parameter, the function computes the rowsum of the counts of each gene and only keeps those genes whose sum is above the CPM.Cutoff in at least the min sample size, so in out case in at least three groups. 

```{r, warning=FALSE,fig.width=10, fig.height=5}
#Normalize for library size, by taking the logCPM
lcpm <- cpm(x, log = T)

#Plot raw logCPM reads before the filtering step
par(mfrow = c(1, 2))
nsamples <- ncol(x)
col <- brewer.pal(nsamples, "Paired")
plot(density(lcpm[, 1]),col = col[1],ylim = c(0, 0.6), las = 2, 
     main = "A. Raw data",
     xlab = expression("log"[2]*"CPM"))
  abline(lty = 3)
    for (i in 2:nsamples) {
        den <- density(lcpm[, i])
        lines(den$x, den$y, col = col[i])
          }

#Filter with filterByExpr function
keep <- filterByExpr(x, group = x$samples$group,
                     lib.size = x$samples$lib.size)
x_Filtered <- x[keep, keep.lib.sizes = FALSE]

#Normalize gene counts after filtering out low counts
lcpm_x_Filtered <- cpm(x_Filtered, log = T)

#Plot logCPM of the filtered dataset
plot(density(lcpm_x_Filtered[, 1]),col = col[1],ylim = c(0, 0.6), las = 2,
     main = "B.filterByExpr",
     xlab = expression("log"[2]*"CPM"))
  abline(lty = 3)
    for (i in 2:nsamples) {
      den <- density(lcpm_x_Filtered[, i])
      lines(den$x, den$y, col = col[i])
        }

```

Number of genes before the filtering step: `r dim(x)[1]` 
\
Number of genes before after filtering step: `r dim(x_Filtered)[1]` 
\

```{r, echo=FALSE}
rm(list=ls()[!(ls() %in% c("gene_counts", "x_Filtered", "lcpm_x_Filtered"))]) #clean the working environment

```


### Normalize gene counts
Now that we filtered out low count genes, we need to normalize our data before making comparisons expression between samples. The gene counts are proportional to the expression levels of RNA, but are also influenced by other factors such as sequencing depth, gene length, and RNA composition. To correct for these factors, we need to normalize the gene counts. One approach to do this, is with TMM normalization (*T*rimmed *M*ean of *M*-values). TMM normalization is a between-samples normalization method: the main goal in TMM normalization is to account for library size variation between samples of interest, accounting for the fact that some extremely differentially expressed genes would impact negatively the normalization procedure. To account for this TMM assumes that most of the genes are not differentially expressed between samples. Therefore, the normalization is performed after calculating a trimmed mean, i.e. the average after removing the upper and lower x% of the data [REF](https://genomebiology.biomedcentral.com/articles/10.1186/gb-2010-11-3-r25). The goal of the TMM normalization is to perform comparisons between the same genes in different samples. Since same genes in different samples are assumed to have the same length, this normalization method does not take into account gene length. 

```{r, fig.show='hide'}

x_Filtered_TMM <- calcNormFactors(x_Filtered, method = "TMM") #TMM normalization (trimmed mean of M-values)

#boxplot to check effect normalization (with outliers)
lcpm_x_Filtered_TMM <- cpm(x_Filtered_TMM, log = TRUE) #calculate lcpm normalized data
par(mfrow=c(1,2))
boxplot(lcpm_x_Filtered, las= 3, outline = TRUE, main = "Not normalized", ylab = expression("log"[2]*"CPM"))
boxplot(lcpm_x_Filtered_TMM, las = 3, outline = TRUE, main = "Normalized", ylab = expression("log"[2]*"CPM"))

```

We can check the effect of the normalization in a boxplot:

```{r fig.width=10, fig.height=5, echo=FALSE}
par(mfrow=c(1,2))
boxplot(lcpm_x_Filtered, las= 3, outline = TRUE, main = "Not normalized", ylab = expression("log"[2]*"CPM"))
boxplot(lcpm_x_Filtered_TMM, las = 3, outline = TRUE, main = "Normalized", ylab = expression("log"[2]*"CPM"))

```

## Unsupervised clustering

In our opinion, one of the most important exploratory plots to examine for gene expression analyses is the multi- dimensional scaling (MDS) plot, or similar. The plot shows similarities and dissimilarities between samples in an unsupervised manner so that one can have an idea of the extent to which differential expression can be detected before carrying out formal tests. Ideally, samples would cluster well within the primary condition of inter- est, and any sample straying far from its group could be identified and followed up for sources of error or extra variation. If present, technical replicates should lie very close to one another.
Such a plot can be made in limma using the plotMDS function. The first dimension represents the leading-fold- change that best separates samples and explains the largest proportion of variation in the data, with subsequent dimensions having a smaller effect and being orthogonal to the ones before it. When experimental design involves multiple factors, it is recommended that each factor is examined over several dimensions. If samples cluster by a given factor in any of these dimensions, it suggests that the factor contributes to expression differences and is worth including in the linear modelling. On the other hand, factors that show little or no effect may be left out of downstream analysis.
Whilst all samples cluster by groups, the largest transcriptional differ- ence is observed between basal and LP, and basal and ML over dimension 1. For this reason, it is expected that pairwise comparisons between cell populations will result in a greater number of DE genes for comparisons involving basal samples, and relatively small numbers of DE genes when comparing ML to LP. Datasets where samples do not cluster by experimental group may show little or no evidence of differential expression in the downstream analysis.



Unsupervised clustering keeping all the samples in. Samples are then then labelled differently to see which condition/parameter separates them better. So the graph is the same, but the labeling (based on C/N ratio, dilution rate or nitrogen source) is different and allows me to see if any of this conditions is separating the samples the most. 

```{r, warning=FALSE, fig.width=10, fig.height=10}

#Generate MDS plots: good to see if there are any outliers in the data and to see what's clustering
#MDS plot for all the samples, colored by different conditions
par(mfrow = c(2, 2))
col.group <- x_Filtered_TMM$samples$Strain
levels(col.group) <- brewer.pal(nlevels(col.group), "Set1")
col.group <- as.character(col.group)
plotMDS(lcpm_x_Filtered_TMM, labels = x_Filtered_TMM$samples$Strain,col = col.group)
title(main = "A. All Samples by Strain")

col.group <- x_Filtered_TMM$samples$NitrogenSource
levels(col.group) <- brewer.pal(nlevels(col.group), "Set1")
col.group <- as.character(col.group)
plotMDS(lcpm_x_Filtered_TMM, labels = x_Filtered_TMM$samples$NitrogenSource,col = col.group)
title(main = "B. All Samples by Nitrogen Source")

col.group <- x_Filtered_TMM$samples$CN_Ratio
levels(col.group) <- brewer.pal(nlevels(col.group), "Set1")
col.group <- as.character(col.group)
plotMDS(lcpm_x_Filtered_TMM, labels = x_Filtered_TMM$samples$CN_Ratio,col = col.group)
title(main = "C. All Samples by CN Ratio")

col.group <- x_Filtered_TMM$samples$DR
levels(col.group) <- brewer.pal(nlevels(col.group), "Set1")
col.group <- as.character(col.group)
plotMDS(lcpm_x_Filtered_TMM, labels = x_Filtered_TMM$samples$DR, col = col.group)
title(main = "D. All Samples by DR")

```

## Differential gene expression analysis

From the PCA, we see that the Q4 strain clusters differently from the O29 and O49, but only when C/N is 116, not 3. Therefore, here i will compare Q4 vs O29 on C/N 116, DR 0.1 and AS as N source. As sanity check, i will also compare O29 with O49 on the same condition. 

### Subset

```{r subset}
Subset <- x_Filtered_TMM[,which(x_Filtered_TMM$samples$CN_Ratio == "116" &
                                  x_Filtered_TMM$samples$NitrogenSource == "Ammonium Sulphate" &
                                  x_Filtered_TMM$samples$DR == "0.1")]

```

### Create design matrix
I choose to create a variable called group in which i combined the different strains and dilution rates in order to make comparisons easier later on. I also decided to use a means model (~ 0 + group) since it makes analysis more clear later on. As documented in the limma guide (DOI: 10.12688/f1000research.27893.1) the two design are equivalent for categorical variables.

```{r}
#Define levels for design matrix
group <- Subset$samples$Strain
  
#Design model matrix
design <- model.matrix(~ 0 + group, data = Subset) #define design matrix
rownames(design) <- rownames(Subset$samples)
colnames(design) <- gsub("group", "", colnames(design))
design #check the design matrix

```

### Create contrast matrix
Create the contrast matrix and set the contrasts that will be analysed by the model

```{r}
contr.matrix <- makeContrasts(
   JFYL007vsOKYL029 = JFYL007 - OKYL029,
   JFYL007vsOKYL049 = JFYL007 - OKYL049,
   OKYL049vsOKYL029 = OKYL049 - OKYL029,
   levels = colnames(design))
contr.matrix

```

## Voom transformation
Limma works with voom transformed data, so perform a voom transformation and then fit the model.  
Mean-variance relationship of log-CPM values: typically, the “voom-plot” shows a decreasing trend between the means and variances resulting from a combination of technical variation in the sequencing experiment and biological variation among the replicate samples from different cell populations. Experiments with high biological variation usually result in flatter trends, where variance values plateau at high expression values. Experiments with low biological variation tend to result in sharp decreasing trends.  
Moreover, the voom-plot provides a visual check on the level of filtering performed upstream. If filtering of lowly- expressed genes is insufficient, a drop in variance levels can be observed at the low end of the expression scale due to very small counts. If this is observed, one should return to the earlier filtering step and increase the expression threshold applied to the dataset.  

```{r}
v <- voom(Subset, design, plot = TRUE) #voom transform

```

### Fit the model
Linear modelling in limma is carried out using the lmFit and contrasts.fit functions originally written for application to microarrays. The functions can be used for both microarray and RNA-seq data and fit a separate model to the expression values for each gene. Next, empirical Bayes moderation is carried out by borrowing information across all genes to obtain more precise estimates of gene-wise variability. The model’s residual variances are plotted against average expression values. It can be seen from this plot that the variance is no longer dependent on the mean expression level.

```{r}
#Linear modelling and empirical Bayes moderation
vfit <- lmFit(v, design)
vfit <- contrasts.fit(vfit, contrasts=contr.matrix) 
efit <- eBayes(vfit)
plotSA(efit)

```

For a quick look at differential expression levels, the number of significantly up- and down-regulated genes can be summarised in a table. Significance is defined using an adjusted p-value cutoff that is set at 5% by default.

```{r fig.height=4, fig.width=10}
summary(decideTests(efit))

par(mfrow = c(1,3))
for (i in 1:ncol(contr.matrix)) {
   plotMD(efit, column = i)
}

```

### Check p value distribution
Check the pvalue distributions. Read more here: http://varianceexplained.org/statistics/interpreting-pvalue-histogram/

```{r fig.height=4,fig.width=10}

#move the results of the comparisons in a list
comp_list <- list()
for (i in 1:ncol(contr.matrix)) {
   name = colnames(contr.matrix)[i]
   tmp = topTreat(efit, coef = i, n = Inf) 
   comp_list[[name]] <- tmp
}

#plot the p value distribution
par(mfrow = c(1,3))
for (i in 1:length(comp_list)) {
   name = names(comp_list[i])
   hist(as.vector(comp_list[[i]][[5]]), main = name, xlab = "P-Value")
}

save(comp_list, file = "../results/Comparison_Output/comp_list_CN116.RData")

```

### Volcano plot

```{r, fig.width=8, fig.height=6, warning=FALSE}
for (i in 1:length(comp_list)) {
        plot <- EnhancedVolcano(comp_list[[i]],
                        lab = NA,
                        x = "logFC",
                        y = "P.Value",
                        pCutoff = 0.01,
                        FCcutoff = 1,
                        ylim = c(0,15),
                        title = paste0(names(comp_list[i])),
                        subtitle = NULL,
                        xlim = c(-6,6),
                        )
  print(plot)
}


```

# Gene set analysis
